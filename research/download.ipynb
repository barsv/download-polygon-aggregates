{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819a835c",
   "metadata": {},
   "source": [
    "code here downloads aggregates (bars) for a given ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0cd06e",
   "metadata": {},
   "source": [
    "1. put api key into secret.txt file next to the download.ipynb\n",
    "2. change the list of tickers and set the timeframe (timespan and multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40fb2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded list of tickers\n",
    "TICKERS = ['SPY']  # Modify this list as needed\n",
    "\n",
    "timespan = 'minute' # second, minute, hour, day, week, month, quarter, year\n",
    "multiplier = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850d3060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polygon-api-client in /home/stan/src/download-polygon-aggregates/.venv/lib/python3.10/site-packages (1.14.6)\n",
      "Requirement already satisfied: pandas in /home/stan/src/download-polygon-aggregates/.venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: python-dateutil in /home/stan/src/download-polygon-aggregates/.venv/lib/python3.10/site-packages (2.9.0.post0)\n",
      "Requirement already satisfied: certifi<2026.0.0,>=2022.5.18 in /home/stan/src/download-polygon-aggregates/.venv/lib/python3.10/site-packages (from polygon-api-client) (2025.4.26)\n",
      "Requirement already satisfied: websockets<15.0,>=10.3 in /home/stan/src/download-polygon-aggregates/.venv/lib/python3.10/site-packages (from polygon-api-client) (14.2)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.9 in /home/stan/src/download-polygon-aggregates/.venv/lib/python3.10/site-packages (from polygon-api-client) (2.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/stan/src/download-polygon-aggregates/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/stan/src/download-polygon-aggregates/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/stan/src/download-polygon-aggregates/.venv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/stan/src/download-polygon-aggregates/.venv/lib/python3.10/site-packages (from python-dateutil) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install polygon-api-client pandas python-dateutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a3cd2",
   "metadata": {},
   "source": [
    "start the download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f87389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-14 14:24:13,929 - INFO - Successfully read API key from secret.txt\n",
      "2025-06-14 14:24:13,931 - INFO - Processing ticker: SPY\n",
      "2025-06-14 14:24:13,931 - INFO - Fetching data for SPY from 2003-01-01 to 2004-01-01\n",
      "2025-06-14 14:24:15,795 - INFO - Retrieved 38762 records for SPY\n",
      "2025-06-14 14:24:15,840 - INFO - Saving to ./stock_data/SPY.csv\n",
      "2025-06-14 14:24:15,952 - INFO - Saved 38762 records to ./stock_data/SPY.csv\n",
      "2025-06-14 14:24:15,954 - INFO - Fetching data for SPY from 2004-01-02 to 2005-01-01\n",
      "2025-06-14 14:24:17,174 - INFO - Retrieved 50000 records for SPY\n",
      "2025-06-14 14:24:18,647 - INFO - Retrieved 100000 records for SPY\n",
      "2025-06-14 14:24:19,557 - INFO - Retrieved 126259 records for SPY\n",
      "2025-06-14 14:24:19,696 - INFO - Saving to ./stock_data/SPY.csv\n",
      "2025-06-14 14:24:20,041 - INFO - Saved 126259 records to ./stock_data/SPY.csv\n",
      "2025-06-14 14:24:20,045 - INFO - Fetching data for SPY from 2005-01-02 to 2006-01-02\n",
      "2025-06-14 14:24:21,814 - INFO - Retrieved 50000 records for SPY\n",
      "2025-06-14 14:24:23,393 - INFO - Retrieved 100000 records for SPY\n",
      "2025-06-14 14:24:24,597 - INFO - Retrieved 132209 records for SPY\n",
      "2025-06-14 14:24:24,779 - INFO - Saving to ./stock_data/SPY.csv\n",
      "2025-06-14 14:24:25,158 - INFO - Saved 132209 records to ./stock_data/SPY.csv\n",
      "2025-06-14 14:24:25,163 - INFO - Fetching data for SPY from 2006-01-03 to 2007-01-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 140\u001b[0m\n\u001b[1;32m    137\u001b[0m         process_ticker(ticker, START_DATE, END_DATE)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 137\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m TICKERS:\n\u001b[1;32m    136\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing ticker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mprocess_ticker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTART_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_DATE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 126\u001b[0m, in \u001b[0;36mprocess_ticker\u001b[0;34m(ticker, start_date, end_date)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current_start \u001b[38;5;241m<\u001b[39m end:\n\u001b[1;32m    125\u001b[0m     current_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(current_start \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39mCHUNK_DAYS), end)\n\u001b[0;32m--> 126\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_aggs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_start\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_end\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     save_to_csv(ticker, data)\n\u001b[1;32m    128\u001b[0m     current_start \u001b[38;5;241m=\u001b[39m current_end \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 76\u001b[0m, in \u001b[0;36mfetch_aggs\u001b[0;34m(ticker, start_date, end_date)\u001b[0m\n\u001b[1;32m     64\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agg \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mlist_aggs(\n\u001b[1;32m     66\u001b[0m     ticker\u001b[38;5;241m=\u001b[39mticker,\n\u001b[1;32m     67\u001b[0m     multiplier\u001b[38;5;241m=\u001b[39mmultiplier,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m     limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m\n\u001b[1;32m     74\u001b[0m ):\n\u001b[1;32m     75\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mconvert_to_et\u001b[49m\u001b[43m(\u001b[49m\u001b[43magg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m: agg\u001b[38;5;241m.\u001b[39mopen,\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m: agg\u001b[38;5;241m.\u001b[39mhigh,\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m: agg\u001b[38;5;241m.\u001b[39mlow,\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m: agg\u001b[38;5;241m.\u001b[39mclose,\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m: agg\u001b[38;5;241m.\u001b[39mvolume,\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvwap\u001b[39m\u001b[38;5;124m'\u001b[39m: agg\u001b[38;5;241m.\u001b[39mvwap,\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransactions\u001b[39m\u001b[38;5;124m'\u001b[39m: agg\u001b[38;5;241m.\u001b[39mtransactions,\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124motc\u001b[39m\u001b[38;5;124m'\u001b[39m: agg\u001b[38;5;241m.\u001b[39motc\n\u001b[1;32m     85\u001b[0m     })\n\u001b[1;32m     86\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m50\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[6], line 53\u001b[0m, in \u001b[0;36mconvert_to_et\u001b[0;34m(timestamp_ms)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_to_et\u001b[39m(timestamp_ms):\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert Unix timestamp (ms) in UTC to Eastern Time (ET) datetime string.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     utc_time \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutcfromtimestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestamp_ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtzinfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtzutc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     et_time \u001b[38;5;241m=\u001b[39m utc_time\u001b[38;5;241m.\u001b[39mastimezone(tz\u001b[38;5;241m.\u001b[39mgettz(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmerica/New_York\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m et_time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from polygon import RESTClient\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from dateutil import tz\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        # logging.FileHandler('polygon_download.log'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Read API key from secret.txt\n",
    "def read_api_key(file_path='secret.txt'):\n",
    "    \"\"\"Read API key from secret.txt.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            api_key = f.read().strip()\n",
    "        logger.info(\"Successfully read API key from secret.txt\")\n",
    "        return api_key\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading API key from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Polygon API client\n",
    "API_KEY = read_api_key()\n",
    "if not API_KEY:\n",
    "    logger.error(\"No API key provided. Exiting.\")\n",
    "    sys.exit(1)\n",
    "client = RESTClient(API_KEY)\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_DIR = './stock_data/'  # Directory to save CSV files\n",
    "START_DATE = '2003-01-01'  # Start date for historical data\n",
    "END_DATE = datetime.now().strftime('%Y-%m-%d')  # Current date\n",
    "CHUNK_DAYS = 365  # Process one year at a time to manage memory\n",
    "RETRY_LIMIT = 3  # Number of retries for API failures\n",
    "RETRY_DELAY = 5  # Seconds to wait between retries\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def convert_to_et(timestamp_ms):\n",
    "    \"\"\"Convert Unix timestamp (ms) in UTC to Eastern Time (ET) datetime string.\"\"\"\n",
    "    utc_time = datetime.utcfromtimestamp(timestamp_ms / 1000).replace(tzinfo=tz.tzutc())\n",
    "    et_time = utc_time.astimezone(tz.gettz('America/New_York'))\n",
    "    return et_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def fetch_aggs(ticker, start_date, end_date):\n",
    "    \"\"\"Fetch second-by-second aggregates for a ticker within a date range.\"\"\"\n",
    "    data = []\n",
    "    attempt = 0\n",
    "    while attempt < RETRY_LIMIT:\n",
    "        try:\n",
    "            logger.info(f\"Fetching data for {ticker} from {start_date} to {end_date}\")\n",
    "            counter = 0\n",
    "            for agg in client.list_aggs(\n",
    "                ticker=ticker,\n",
    "                multiplier=multiplier,\n",
    "                timespan=timespan,\n",
    "                from_=start_date,\n",
    "                to=end_date,\n",
    "                adjusted=True,\n",
    "                sort='asc',\n",
    "                limit=50000\n",
    "            ):\n",
    "                data.append({\n",
    "                    'timestamp': convert_to_et(agg.timestamp),\n",
    "                    'open': agg.open,\n",
    "                    'high': agg.high,\n",
    "                    'low': agg.low,\n",
    "                    'close': agg.close,\n",
    "                    'volume': agg.volume,\n",
    "                    'vwap': agg.vwap,\n",
    "                    'transactions': agg.transactions,\n",
    "                    'otc': agg.otc\n",
    "                })\n",
    "                counter += 1\n",
    "                if counter % (50 * 1000) == 0:\n",
    "                    logger.info(f\"Retrieved {counter} records for {ticker}\")\n",
    "            logger.info(f\"Retrieved {len(data)} records for {ticker}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            logger.warning(f\"Attempt {attempt}/{RETRY_LIMIT} failed for {ticker}: {e}\")\n",
    "            if attempt < RETRY_LIMIT:\n",
    "                time.sleep(RETRY_DELAY)\n",
    "            else:\n",
    "                logger.error(f\"Failed to fetch data for {ticker} after {RETRY_LIMIT} attempts\")\n",
    "                return []\n",
    "\n",
    "def save_to_csv(ticker, data):\n",
    "    \"\"\"Save data to a CSV file, appending if the file exists.\"\"\"\n",
    "    if not data:\n",
    "        logger.warning(f\"No data to save for {ticker}\")\n",
    "        return\n",
    "    df = pd.DataFrame(data)\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"{ticker}.csv\")\n",
    "    logger.info(f\"Saving to {output_path}\")\n",
    "    try:\n",
    "        if os.path.exists(output_path):\n",
    "            # Append to existing file, avoid duplicating headers\n",
    "            df.to_csv(output_path, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            df.to_csv(output_path, mode='w', header=True, index=False)\n",
    "        logger.info(f\"Saved {len(df)} records to {output_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving CSV for {ticker}: {e}\")\n",
    "\n",
    "def process_ticker(ticker, start_date, end_date):\n",
    "    \"\"\"Process a single ticker, fetching data in chunks.\"\"\"\n",
    "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    current_start = start\n",
    "\n",
    "    while current_start < end:\n",
    "        current_end = min(current_start + timedelta(days=CHUNK_DAYS), end)\n",
    "        data = fetch_aggs(ticker, current_start.strftime('%Y-%m-%d'), current_end.strftime('%Y-%m-%d'))\n",
    "        save_to_csv(ticker, data)\n",
    "        current_start = current_end + timedelta(days=1)\n",
    "\n",
    "def main():\n",
    "    if not TICKERS:\n",
    "        logger.error(\"No tickers defined. Exiting.\")\n",
    "        return\n",
    "\n",
    "    for ticker in TICKERS:\n",
    "        logger.info(f\"Processing ticker: {ticker}\")\n",
    "        process_ticker(ticker, START_DATE, END_DATE)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
