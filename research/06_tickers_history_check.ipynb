{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "in this notebook i checked what was downloaded by download_tickers_history.py.\n",
    "\n",
    "i check that i have active and inactive tickers for all days when exchanges were open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup client for AWS S3\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to Python path to import api_key module\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_dir = os.path.join(settings.ABSOLUTE_DATA_DIR, 'tickers')\n",
    "active_tickers_file = os.path.join(tickers_dir, 'tickers_history_active.csv')\n",
    "inactive_tickers_file = os.path.join(tickers_dir, 'tickers_history_inactive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def collect_unique_dates(file_path):\n",
    "    unique_dates = set()\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader, None)  # skip the first line (header)\n",
    "        prev_date = None\n",
    "        line_counter = 0\n",
    "        for row in reader:\n",
    "            if row:  # skip empty lines\n",
    "                date = row[0]\n",
    "                # optimization: check against the hashset only if the date is different from the previous one\n",
    "                if date != prev_date:\n",
    "                    unique_dates.add(date)\n",
    "                    prev_date = date\n",
    "            else:\n",
    "                print(f\"Empty line found in {file_path} at position {line_counter}, skipping.\")\n",
    "                return None\n",
    "            line_counter += 1\n",
    "    return unique_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dates = collect_unique_dates(active_tickers_file)\n",
    "df = pd.DataFrame(list(dates), columns=['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the DataFrame by date\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(by='Date').reset_index(drop=True)\n",
    "# save the DataFrame to a CSV file\n",
    "df.to_csv(os.path.join(tickers_dir, 'unique_active_dates.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "\n",
    "schedule = nyse.schedule(start_date='2003-09-10', end_date='2025-06-11')\n",
    "# get dates from the schedule\n",
    "schedule_dates = pd.Series(schedule.index.date)\n",
    "schedule_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df['Date'] to datetime\n",
    "active_dates = pd.Series(pd.to_datetime(df['Date']).dt.date)\n",
    "active_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that unique_days are in the NYSE schedule\n",
    "print(schedule_dates.isin(active_dates).all())\n",
    "# and that the NYSE schedule is in unique_days\n",
    "print(active_dates.isin(schedule_dates).all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "this True, False result is expected because active_dates were downloaded for all days except weekends. means that it has dates for federal holidays and also days of disasters when exchanges were closed. one more check below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dates that are in schedule_dates but not in active_dates\n",
    "missing_in_active = schedule_dates[~schedule_dates.isin(active_dates)]\n",
    "print(\"Dates in NYSE schedule but not in active dates:\")\n",
    "print(missing_in_active)\n",
    "\n",
    "# Find dates that are in active_dates but not in schedule_dates\n",
    "extra_in_active = active_dates[~active_dates.isin(schedule_dates)]\n",
    "print(\"Dates in active dates but not in NYSE schedule:\")\n",
    "print(extra_in_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the same for inactive tickers\n",
    "inactive_dates = collect_unique_dates(inactive_tickers_file)\n",
    "\n",
    "df = pd.DataFrame(list(inactive_dates), columns=['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(by='Date').reset_index(drop=True)\n",
    "# save the DataFrame to a CSV file\n",
    "df.to_csv(os.path.join(tickers_dir, 'unique_inactive_dates.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "inactive_dates = pd.Series(pd.to_datetime(df['Date']).dt.date)\n",
    "inactive_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that unique_days are in the NYSE schedule\n",
    "print(schedule_dates.isin(active_dates).all())\n",
    "# and that the NYSE schedule is in unique_days\n",
    "print(active_dates.isin(schedule_dates).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "ok. so i have active and inactive tickers for all days when exchanges were open. next step is to try to calculate renames."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
