{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e727766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nin this notebook i\\'m trying to get renames for all (active and inactive) tickers.\\n\\nwhat i\\'ve found so far.\\n\\n1) there are a lot of cases when polygon doesn\\'t provide figi for a ticker. and this happens not only for tickers that \\n    were delisted before a figi was assigned. it happens even for active companies where tradingview shows their figi.\\n    for example, XP BBG00QVJYGM9 is trading already 5 years starting from 2020. the ticker XP is present but no figi.\\n\\n2) for 1 figi sometimes there are more than one ticker at the same time. some examples:\\n\\n```\\n    2025-05-30,VLGE.A,BBG000BWGK40,True,          ,usd,,2016-05-18T00:00:00Z,us,stocks,VILLAGE SUPER MARKET CL-A NEW,XNAS,\\n    2025-05-30,VLGEA ,BBG000BWGK40,True,0000103595,usd,,2025-05-30T00:00:00Z,us,stocks,Village Super Market         ,XNAS,CS\\n```\\n\\n\\n    here tickers will be the same if \\'.\\' is removed but look at the next case:\\n\\n```\\n    2012-04-24,ABD  ,BBG000J06K07,True,0000712034,usd,,2012-04-26T00:00:00Z,us,stocks,ACCO BRANDS CORPORATION,XNYS,CS\\n    2012-04-24,ACCOw,BBG000J06K07,True,0000712034,usd,,2012-04-30T00:00:00Z,us,stocks,ACCO BRANDS CORPORATION W.I.,XNYS,\\n```\\n\\n    usually warrants are with \\'w\\' suffix but here the whole ticker is different.\\n\\n3) sometimes there are complete duplicates. for example, \\nhttps://api.polygon.io/v3/reference/tickers?ticker=UST&market=stocks&date=2025-06-01&active=true&order=asc&limit=100&sort=ticker&apiKey= \\n\\nreturns:\\n\\n```\\n    {\\n    \"results\": [\\n        {\\n        \"ticker\": \"UST\",\\n        \"name\": \"ProShares Ultra 7-10 Year Treasury\",\\n        \"market\": \"stocks\",\\n        \"locale\": \"us\",\\n        \"primary_exchange\": \"ARCX\",\\n        \"type\": \"ETF\",\\n        \"active\": true,\\n        \"currency_name\": \"usd\",\\n        \"composite_figi\": \"BBG000BH4371\",\\n        \"share_class_figi\": \"BBG001SK30C5\",\\n        \"last_updated_utc\": \"2024-09-23T00:00:00Z\"\\n        },\\n        {\\n        \"ticker\": \"UST\",\\n        \"name\": \"ProShares Ultra 7-10 Year Treasury\",\\n        \"market\": \"stocks\",\\n        \"locale\": \"us\",\\n        \"primary_exchange\": \"ARCX\",\\n        \"type\": \"ETF\",\\n        \"active\": true,\\n        \"currency_name\": \"usd\",\\n        \"cik\": \"0001373525\",\\n        \"composite_figi\": \"BBG000BH4371\",\\n        \"share_class_figi\": \"BBG001SK30C5\",\\n        \"last_updated_utc\": \"2025-06-02T00:00:00Z\"\\n        }\\n    ],\\n    \"status\": \"OK\",\\n    \"request_id\": \"54d441e0bb407fc21739f13b8a5af347\",\\n    \"count\": 2\\n    }\\n```\\n\\n    the only difference is cik.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "in this notebook i'm trying to get renames for all (active and inactive) tickers.\n",
    "\n",
    "what i've found so far.\n",
    "\n",
    "1) there are a lot of cases when polygon doesn't provide figi for a ticker. and this happens not only for tickers that \n",
    "    were delisted before a figi was assigned. it happens even for active companies where tradingview shows their figi.\n",
    "    for example, XP BBG00QVJYGM9 is trading already 5 years starting from 2020. the ticker XP is present but no figi.\n",
    "\n",
    "2) for 1 figi sometimes there are more than one ticker at the same time. some examples:\n",
    "\n",
    "```\n",
    "    2025-05-30,VLGE.A,BBG000BWGK40,True,          ,usd,,2016-05-18T00:00:00Z,us,stocks,VILLAGE SUPER MARKET CL-A NEW,XNAS,\n",
    "    2025-05-30,VLGEA ,BBG000BWGK40,True,0000103595,usd,,2025-05-30T00:00:00Z,us,stocks,Village Super Market         ,XNAS,CS\n",
    "```\n",
    "\n",
    "\n",
    "    here tickers will be the same if '.' is removed but look at the next case:\n",
    "\n",
    "```\n",
    "    2012-04-24,ABD  ,BBG000J06K07,True,0000712034,usd,,2012-04-26T00:00:00Z,us,stocks,ACCO BRANDS CORPORATION,XNYS,CS\n",
    "    2012-04-24,ACCOw,BBG000J06K07,True,0000712034,usd,,2012-04-30T00:00:00Z,us,stocks,ACCO BRANDS CORPORATION W.I.,XNYS,\n",
    "```\n",
    "\n",
    "    usually warrants are with 'w' suffix but here the whole ticker is different.\n",
    "\n",
    "3) sometimes there are complete duplicates. for example, \n",
    "https://api.polygon.io/v3/reference/tickers?ticker=UST&market=stocks&date=2025-06-01&active=true&order=asc&limit=100&sort=ticker&apiKey= \n",
    "\n",
    "returns:\n",
    "\n",
    "```\n",
    "    {\n",
    "    \"results\": [\n",
    "        {\n",
    "        \"ticker\": \"UST\",\n",
    "        \"name\": \"ProShares Ultra 7-10 Year Treasury\",\n",
    "        \"market\": \"stocks\",\n",
    "        \"locale\": \"us\",\n",
    "        \"primary_exchange\": \"ARCX\",\n",
    "        \"type\": \"ETF\",\n",
    "        \"active\": true,\n",
    "        \"currency_name\": \"usd\",\n",
    "        \"composite_figi\": \"BBG000BH4371\",\n",
    "        \"share_class_figi\": \"BBG001SK30C5\",\n",
    "        \"last_updated_utc\": \"2024-09-23T00:00:00Z\"\n",
    "        },\n",
    "        {\n",
    "        \"ticker\": \"UST\",\n",
    "        \"name\": \"ProShares Ultra 7-10 Year Treasury\",\n",
    "        \"market\": \"stocks\",\n",
    "        \"locale\": \"us\",\n",
    "        \"primary_exchange\": \"ARCX\",\n",
    "        \"type\": \"ETF\",\n",
    "        \"active\": true,\n",
    "        \"currency_name\": \"usd\",\n",
    "        \"cik\": \"0001373525\",\n",
    "        \"composite_figi\": \"BBG000BH4371\",\n",
    "        \"share_class_figi\": \"BBG001SK30C5\",\n",
    "        \"last_updated_utc\": \"2025-06-02T00:00:00Z\"\n",
    "        }\n",
    "    ],\n",
    "    \"status\": \"OK\",\n",
    "    \"request_id\": \"54d441e0bb407fc21739f13b8a5af347\",\n",
    "    \"count\": 2\n",
    "    }\n",
    "```\n",
    "\n",
    "    the only difference is cik.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb44f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to Python path to import api_key module\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5403e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_dir = os.path.join(settings.ABSOLUTE_DATA_DIR, 'tickers')\n",
    "active_tickers_file = os.path.join(tickers_dir, 'tickers_history_active.csv')\n",
    "inactive_tickers_file = os.path.join(tickers_dir, 'tickers_history_inactive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f38819a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date,ticker,composite_figi,active,cik,currency_name,delisted_utc,last_updated_utc,locale,market,name,primary_exchange,type\n",
      "\n",
      "2003-09-10,A,BBG000C2V3D6,True,0001090872,usd,,2004-06-24T00:00:00Z,us,stocks,\"AGILENT TECHNOLOGIES, INC\",XNYS,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(active_tickers_file, newline='', encoding='utf-8') as fin:\n",
    "    print(fin.readline())  # Print header\n",
    "    print(fin.readline())  # the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d7a5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwhat will not work:\\n- inside a given day figi is not unique, because it\\'s possible to have several tickers for the same figi.\\n- it\\'s not a good idea to try to \"compress\" history by just removing duplicates in the rows because such \\n  \"compressed\" data will loose information about when a ticker disappeared from history.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "what will not work:\n",
    "- inside a given day figi is not unique, because it's possible to have several tickers for the same figi.\n",
    "- it's not a good idea to try to \"compress\" history by just removing duplicates in the rows because such \n",
    "  \"compressed\" data will loose information about when a ticker disappeared from history.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "algorithm:\n",
    "1. loop through active_tickers_file\n",
    "2. collect all rows for the first day.\n",
    "   need to check here that there are no duplicate tickers within one day.\n",
    "   create a dictionary that maps a ticker to its row.\n",
    "3. repeat (2) for the next day.\n",
    "   now loop over all tickers in the current day and compare them to tickers in the previous day.\n",
    "   if there is a change in (composite_figi, active, cik, delisted_utc, name, primary_exchange, type)\n",
    "   then log it into history as history['figi']['ticker']['date']=row.\n",
    "   if there are new tickers then they will be added as well.\n",
    "   when processing a row in the active_today remove it from active_yesterday.\n",
    "   in the end active_yesterday will have tickers that are missing today. add them to the history.\n",
    "   history['figi']['ticker']['date']=null\n",
    "'''\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "history = {}\n",
    "counter = 0\n",
    "active_today = {}\n",
    "active_yesterday = {}\n",
    "\n",
    "with open(active_tickers_file, newline='', encoding='utf-8') as fin:\n",
    "    reader = csv.DictReader(fin)\n",
    "    for row in reader:\n",
    "        counter += 1\n",
    "        if counter % (1000 * 1000) == 0:\n",
    "            print(f\"Processed {counter} rows\")\n",
    "        figi  = row[\"composite_figi\"]\n",
    "        if not figi:\n",
    "            # Skip rows without FIGI\n",
    "            continue\n",
    "        ticker= row[\"ticker\"]\n",
    "        date  = datetime.fromisoformat(row[\"date\"]).date()\n",
    "        if figi not in history:\n",
    "            # first time encountering this FIGI\n",
    "            history[figi] = { ticker: { 'first_active' : date } }\n",
    "        else:\n",
    "            f = history[figi]\n",
    "            if ticker not in f:\n",
    "                # first time encountering this ticker for this FIGI\n",
    "                f[ticker] = { 'first_active' : date }\n",
    "            else:\n",
    "                # known ticker for this FIGI\n",
    "                f[ticker]['last_active'] = date\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe21352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FB': {'first_active': datetime.date(2012, 5, 18),\n",
       "  'last_active': datetime.date(2022, 6, 8)},\n",
       " 'META': {'first_active': datetime.date(2022, 6, 9),\n",
       "  'last_active': datetime.date(2025, 6, 11)}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['BBG000MM2P62']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b847f88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ABDw': {'first_active': datetime.date(2005, 8, 9),\n",
       "  'last_active': datetime.date(2005, 8, 16)},\n",
       " 'ABD': {'first_active': datetime.date(2005, 8, 17),\n",
       "  'last_active': datetime.date(2012, 4, 30)},\n",
       " 'ACCOw': {'first_active': datetime.date(2012, 4, 24),\n",
       "  'last_active': datetime.date(2012, 4, 30)},\n",
       " 'ACCO': {'first_active': datetime.date(2012, 5, 2),\n",
       "  'last_active': datetime.date(2025, 6, 11)}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['BBG000J06K07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now analyze inactive tickers\n",
    "surprise = {}\n",
    "\n",
    "with open(inactive_tickers_file, newline='', encoding='utf-8') as fin:\n",
    "    reader = csv.DictReader(fin)\n",
    "    for row in reader:\n",
    "        counter += 1\n",
    "        if counter % (1000 * 1000) == 0:\n",
    "            print(f\"Processed {counter} rows\")\n",
    "        figi  = row[\"composite_figi\"]\n",
    "        if not figi:\n",
    "            # Skip rows without FIGI\n",
    "            continue\n",
    "        ticker= row[\"ticker\"]\n",
    "        date  = datetime.fromisoformat(row[\"date\"]).date()\n",
    "        if figi not in history:\n",
    "            if figi not in surprise:\n",
    "                surprise[figi] = { ticker : { 'first_time': date, 'unknown_figi': True } }\n",
    "            else:\n",
    "                surprise[figi][ticker]['last_time'] = date\n",
    "            continue\n",
    "        else:\n",
    "            history_figi = history[figi]\n",
    "            if ticker not in history_figi:\n",
    "                # known FIGI, but new ticker\n",
    "                if figi not in surprise:\n",
    "                    surprise[figi] = { ticker: { 'first_time': date, 'unknown_ticker': True } }\n",
    "                elif ticker not in surprise[figi]:\n",
    "                    surprise[figi][ticker] = { 'first_time': date, 'unknown_ticker': True }\n",
    "                else:\n",
    "                    surprise[figi][ticker]['last_time'] = date\n",
    "                continue\n",
    "            else:\n",
    "                history_figi_ticker = history_figi[ticker]\n",
    "                if 'end' not in history_figi_ticker or history_figi_ticker['end'] is None:\n",
    "                    history_figi_ticker['end'] = date\n",
    "                    history_figi_ticker['delisted_utc'] = row['delisted_utc']\n",
    "                else:\n",
    "                    history_figi_ticker['last_inactive'] = date\n",
    "surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e40052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nok. so there are several observations here:\\n\\n1) it happens that there appears a record about inactive ticker with figi while the there were no such figi among \\nactive tickers.\\n\\ni did search manually for BBG00FZLQV86, BBG000F4MYC2, BBG000GQR282 in the active tickers csv and haven\\'t found anything.\\nwhile they can be found in the inactive tickers csv.\\n\\nalso this can be proven via https://polygon.io/docs/rest/stocks/tickers/all-tickers\\nfor example, for CNET on 2020-10-13 there is only one active ticker with \"last_updated_utc\": \"2016-05-18T00:00:00Z\".\\non 2020-10-14 there appears BBG00DP4PXQ7 with \"delisted_utc\": \"2020-10-14T00:00:00Z\". looks like there were 4 years \\nwithout deals for this ticker and figi was not updated until delisting.\\n\\n2) if the figi is known for a ticker then the first deactivation record appears always after active records. means \\nno crap here. but again - it\\'s possible that there were no active records.\\n\\n3) it happens that for a given figi deactivation records stop to appear. a good example is BBG00GVX5D49 that appeared\\nonly once on 2021-08-02.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ok. so there are several observations here:\n",
    "\n",
    "1) it happens that there appears a record about inactive ticker with figi while the there were no such figi among \n",
    "active tickers.\n",
    "\n",
    "i did search manually for BBG00FZLQV86, BBG000F4MYC2, BBG000GQR282 in the active tickers csv and haven't found anything.\n",
    "while they can be found in the inactive tickers csv.\n",
    "\n",
    "also this can be proven via https://polygon.io/docs/rest/stocks/tickers/all-tickers\n",
    "for example, for CNET on 2020-10-13 there is only one active ticker with \"last_updated_utc\": \"2016-05-18T00:00:00Z\".\n",
    "on 2020-10-14 there appears BBG00DP4PXQ7 with \"delisted_utc\": \"2020-10-14T00:00:00Z\". looks like there were 4 years \n",
    "without deals for this ticker and figi was not updated until delisting.\n",
    "\n",
    "2) if the figi is known for a ticker then the first deactivation record appears always after active records. means \n",
    "no crap here. but again - it's possible that there were no active records.\n",
    "\n",
    "3) it happens that for a given figi deactivation records stop to appear. a good example is BBG00GVX5D49 that appeared\n",
    "only once on 2021-08-02.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfdf3e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected dates for BBG000B9XB24 AAME: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000C2LZP3 AAON: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000B9XRY4 AAPL: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000DK5Q25 ABB: last_active=2024-05-17, end=2023-05-23\n",
      "Unexpected dates for BBG000CK8P25 ABMC: last_active=2009-09-02, end=2004-04-19\n",
      "Unexpected dates for BBG000C101X4 ABMD: last_active=2022-12-22, end=2009-10-29\n",
      "Unexpected dates for BBG000HYNQP6 AXAS: last_active=2021-08-03, end=2009-10-29\n",
      "Unexpected dates for BBG00D8FFF27 ACET: last_active=2024-05-17, end=2009-10-29\n",
      "Unexpected dates for BBG000BB2LK1 ACMT.A: last_active=2004-12-03, end=2004-11-08\n",
      "Unexpected dates for BBG000KF9J02 ACTG: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BB5006 ADBE: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000JG0547 ADP: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BM7HL0 ADSK: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000C4K3D4 ADTN: last_active=2022-07-07, end=2009-10-29\n",
      "Unexpected dates for BBG000CKQSN6 AEG: last_active=2025-06-11, end=2023-10-02\n",
      "Unexpected dates for BBG000BWM083 AEHR: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000FKMP26 AEIS: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG00JRSWHF8 AHT: last_active=2024-05-10, end=2020-07-16\n",
      "Unexpected dates for BBG000BBH316 AIRT: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BJQWD2 AKAM: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG00FZLP897 AKS: last_active=2024-05-17, end=2020-03-16\n",
      "Unexpected dates for BBG000BBJR57 ALCO: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BRNLL2 ALGN: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BBMCY4 ALOT: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG00JQ5BPG3 ALSK: last_active=2021-07-22, end=2009-10-29\n",
      "Unexpected dates for BBG00GQGHK61 ALXN: last_active=2021-07-21, end=2009-10-29\n",
      "Unexpected dates for BBG000BBPFB9 AMAT: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000B9ZV28 AMED: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BBS2Y0 AMGN: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BCKGW7 AMKR: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BG8NR3 AMNB: last_active=2024-04-01, end=2009-10-29\n",
      "Unexpected dates for BBG000BKVYJ3 AMOT: last_active=2024-05-17, end=2009-10-29\n",
      "Unexpected dates for BBG000CYNFY5 AMOV: last_active=2023-03-03, end=2009-10-29\n",
      "Unexpected dates for BBG00DBBJ0V9 AMSG: last_active=2024-05-17, end=2009-10-29\n",
      "Unexpected dates for BBG000BBWFN8 AMSW.A: last_active=2024-10-01, end=2004-11-08\n",
      "Unexpected dates for BBG000BBWFN8 AMSWA: last_active=2024-10-01, end=2004-11-09\n",
      "Unexpected dates for BBG000BBJTR9 AMTC: last_active=2012-05-02, end=2009-10-29\n",
      "Unexpected dates for BBG000BBX657 AMWD: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BVPV84 AMZN: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG00KDNVR33 ANAT: last_active=2024-05-17, end=2009-10-29\n",
      "Unexpected dates for BBG000BF8CN3 ANDE: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BBKZD8 ANIK: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000GXZ4W7 ANSS: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BC6L61 APOG: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000FSK9V5 ARCA.F: last_active=2004-12-31, end=2004-11-08\n",
      "Unexpected dates for BBG000FSK9V5 ARCAF: last_active=2007-06-07, end=2004-11-09\n",
      "Unexpected dates for BBG000DMMH86 ARKR: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000C14X88 ARLP: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG000BCBS51 AROW: last_active=2025-06-11, end=2009-10-29\n",
      "Unexpected dates for BBG00JR5L637 ARQL: last_active=2024-05-17, end=2009-10-29\n",
      "Unexpected dates for BBG00D8FGWS1 ARRY: last_active=2024-05-17, end=2009-10-29\n",
      "found enough already\n"
     ]
    }
   ],
   "source": [
    "# the code below shows that it's possible that the ticker remains active even after an inactive record appears.\n",
    "count = 0\n",
    "for figi, tickers in history.items():\n",
    "    for ticker, dates in tickers.items():\n",
    "        last_active_date = dates.get('last_active', None)\n",
    "        end_date = dates.get('end', None)\n",
    "        if last_active_date and end_date and last_active_date > end_date:\n",
    "            # This is a case where the last active date is after the end date, which is unexpected\n",
    "            print(f\"Unexpected dates for {figi} {ticker}: last_active={last_active_date}, end={end_date}\")\n",
    "            count += 1\n",
    "    if count > 50:\n",
    "        print(\"found enough already\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "024f3ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read api_key.txt. Key len 32\n",
      "first check that api works for META\n",
      "TickerChangeResults(name='Meta Platforms, Inc. Class A Common Stock', composite_figi='BBG000MM2P62', cik='0001326801', events=[{'ticker_change': {'ticker': 'META'}, 'type': 'ticker_change', 'date': '2022-06-09'}, {'ticker_change': {'ticker': 'FB'}, 'type': 'ticker_change', 'date': '2012-05-18'}])\n",
      "\n",
      "now check that it doesn't return data for the delisted ticker FNM\n",
      "Error fetching events for FNM: {\"status\":\"NOT_FOUND\",\"request_id\":\"e6d250958318aedc5acdcb19b403f7bc\",\"message\":\"ID not found\"}\n",
      "\n",
      "now check that there are ticker details for FNM in the past:\n",
      "TickerDetails(active=True, address=CompanyAddress(address1='3900 WISCONSIN AVE N.W.', address2=None, city='WASHINGTON', state='DC', country=None, postal_code='20016'), branding=None, cik='0000310522', composite_figi='BBG000BJQ328', currency_name='usd', currency_symbol=None, base_currency_name=None, base_currency_symbol=None, delisted_utc=None, description=None, ticker_root='FNM', ticker_suffix=None, homepage_url=None, list_date=None, locale='us', market='stocks', market_cap=None, name='FANNIE MAE', phone_number='(202) 752-7000', primary_exchange='XNYS', share_class_figi='BBG001S5R8W3', share_class_shares_outstanding=1129090420, sic_code='6111', sic_description='FEDERAL & FEDERALLY-SPONSORED CREDIT AGENCIES', ticker='FNM', total_employees=None, type='CS', weighted_shares_outstanding=None)\n",
      "\n",
      "and there are aggregates for FNM in the past:\n",
      "[Agg(open=70.3, high=71.46, low=70.3, close=70.42, volume=3725100.0, vwap=70.9135, timestamp=1099285200000, transactions=5426, otc=None), Agg(open=70.22, high=71.72, low=69.85, close=71.44, volume=4019800.0, vwap=71.0068, timestamp=1099371600000, transactions=5614, otc=None)]\n"
     ]
    }
   ],
   "source": [
    "# more observations\n",
    "# ticker events api doesn't have data for delisted tickers. for example:\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to Python path to import api_key module\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "import api_key\n",
    "from polygon import RESTClient\n",
    "\n",
    "API_KEY = api_key.read_api_key()\n",
    "client = RESTClient(API_KEY)\n",
    "\n",
    "print(\"first check that api works for META\")\n",
    "events = client.get_ticker_events('META')\n",
    "print(events)\n",
    "\n",
    "print()\n",
    "print(\"now check that it doesn't return data for the delisted ticker FNM\")\n",
    "try:\n",
    "    events = client.get_ticker_events('FNM')\n",
    "    print(events)\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching events for FNM: {e}\")\n",
    "\n",
    "print()\n",
    "print(\"now check that there are ticker details for FNM in the past:\")\n",
    "details = client.get_ticker_details('FNM', '2004-11-01')\n",
    "print(details)\n",
    "\n",
    "print()\n",
    "print(\"and there are aggregates for FNM in the past:\")\n",
    "aggs = client.get_aggs('FNM', 1, 'day', '2004-11-01', '2004-11-02')\n",
    "print(aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9320348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ticker events API says that FORTY was renamed from FORT on 2004-11-08:\n",
      "\n",
      "{'ticker_change': {'ticker': 'FORTY'}, 'type': 'ticker_change', 'date': '2004-11-08'}\n",
      "{'ticker_change': {'ticker': 'FORT'}, 'type': 'ticker_change', 'date': '2003-09-10'}\n",
      "\n",
      "# that is wrong because it was trading under ticker FORTY since the beginning. see in aggregates API:\n",
      "FORTY from 2003-09-10 to 2003-09-10: [Agg(open=12.13, high=12.18, low=12, close=12, volume=6100, vwap=12.03, timestamp=1063166400000, transactions=13, otc=None)]\n",
      "1063166400000 is 2003-09-10\n",
      "\n",
      "# proof from flat files that FORTY was traded under ticker FORTY on 2003-09-10:\n",
      "ticker,conditions,correction,exchange,id,participant_timestamp,price,sequence_number,sip_timestamp      ,size,tape,trf_id,trf_timestamp\n",
      "\n",
      "FORTY,           ,0         ,11      ,  ,0                    ,12.13,54390          ,1063200772000000000,500 ,3   ,0,0\n",
      "FORTY,,0,12,,0,12.18,54683,1063200774000000000,500,3,0,0\n",
      "FORTY,,0,12,,0,12.02,164233,1063201566000000000,100,3,0,0\n",
      "FORTY,,0,12,,0,12,164235,1063201566000000000,300,3,0,0\n",
      "FORTY,,0,12,,0,12,186085,1063201737000000000,700,3,0,0\n",
      "FORTY,,0,3,,0,12.01,186176,1063201738000000000,300,3,0,0\n",
      "FORTY,,0,12,,0,12.02,405193,1063203807000000000,100,3,0,0\n",
      "FORTY,,0,12,,0,12.01,405213,1063203808000000000,200,3,0,0\n",
      "FORTY,,0,12,,0,12.011,451218,1063204318000000000,100,3,0,0\n",
      "FORTY,,0,12,,0,12.01,1255112,1063218714000000000,1800,3,0,0\n",
      "FORTY,,0,12,,0,12,1255113,1063218714000000000,200,3,0,0\n",
      "FORTY,,0,12,,0,12,1257062,1063218737000000000,1200,3,0,0\n",
      "FORTY,,0,3,,0,12,1257254,1063218739000000000,100,3,0,0\n",
      "FORTY,15,0,12,,0,12,1743433,1063224092000000000,0,3,0,0\n",
      "FORTY,15,0,3,,0,12,1746692,1063224185000000000,0,3,0,0\n",
      "\n",
      "\n",
      "# and it was never traded as FORT and FORT.Y ever:\n",
      "FORT from 2003-09-10 to 2025-06-11: []\n",
      "FORT.Y from 2003-09-10 to 2025-06-11: []\n",
      "\n",
      "# ticker details API also is wrong because it doesn't find FORTY before 2004-11-08:\n",
      "Error fetching details for FORTY on 2004-11-01: {\"status\":\"NOT_FOUND\",\"request_id\":\"bfa5e71860f69bb9d1c904b7cc77de6d\",\"message\":\"Ticker not found.\"}\n",
      "2004-11-01 is a Monday\n",
      "\n",
      "# while there were trades on 2004-11-01:\n",
      "FORTY from 2004-11-01 to 2004-11-01: [Agg(open=15, high=15.3, low=15, close=15.01, volume=1050, vwap=15.1141, timestamp=1099285200000, transactions=9, otc=None)]\n",
      "\n",
      "# the same on 2003-09-10:\n",
      "Error fetching details for FORTY on 2003-09-10: {\"status\":\"NOT_FOUND\",\"request_id\":\"470a72f2fae7bf4ae52d9aa3346e2390\",\"message\":\"Ticker not found.\"}\n",
      "\n",
      "# trades:\n",
      "FORTY from 2003-09-10 to 2003-09-10: [Agg(open=12.13, high=12.18, low=12, close=12, volume=6100, vwap=12.03, timestamp=1063166400000, transactions=13, otc=None)]\n",
      "\n",
      "# history collected from active tickers also is not good because FORTY appears in it only in on 2004-11-08.\n",
      "history[\"BBG000JLM9R9\"] = {\n",
      "FORT.Y: {'first_active': datetime.date(2003, 9, 10), 'last_active': datetime.date(2025, 6, 11), 'end': datetime.date(2004, 11, 8), 'delisted_utc': '2004-11-08T00:00:00Z', 'last_inactive': datetime.date(2012, 12, 13)}\n",
      "FORTY: {'first_active': datetime.date(2004, 11, 8), 'last_active': datetime.date(2025, 6, 11), 'end': datetime.date(2004, 11, 9), 'delisted_utc': '2004-11-09T00:00:00Z', 'last_inactive': datetime.date(2025, 6, 12)}\n",
      "}\n",
      "# before 2004-11-08 there is no FORTY in tickers history. there is only FORT.Y for which there is no data in aggregates API.\n"
     ]
    }
   ],
   "source": [
    "# but in fact from history analysis i can see:\n",
    "def print_details(ticker, date):\n",
    "    try:\n",
    "        details = client.get_ticker_details(ticker, date)\n",
    "        print(f'{ticker} on {date}: {details}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching details for {ticker} on {date}: {e}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def timestamp_to_date(timestamp):\n",
    "    try:\n",
    "        date = pd.to_datetime(timestamp, unit='ms').date()\n",
    "        return date\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting timestamp {timestamp} to date: {e}\")\n",
    "        return None\n",
    "\n",
    "def print_day_of_week(date):\n",
    "    try:\n",
    "        day_of_week = pd.to_datetime(date).day_name()\n",
    "        print(f'{date} is a {day_of_week}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching day of week for {date}: {e}\")\n",
    "\n",
    "def print_aggs(ticker, start_date, end_date):\n",
    "    try:\n",
    "        aggs = client.get_aggs(ticker, 1, 'day', start_date, end_date)\n",
    "        print(f'{ticker} from {start_date} to {end_date}: {aggs}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching aggregates for {ticker} from {start_date} to {end_date}: {e}\")\n",
    "\n",
    "def pretty_print_map(data):\n",
    "    for key, value in data.items():\n",
    "        print(f'{key}: {value}')\n",
    "\n",
    "print(\"# ticker events API says that FORTY was renamed from FORT on 2004-11-08:\")\n",
    "print()\n",
    "# sometimes ticker events API is missleading.\n",
    "# for example, for FORTY it says that there was a ticker change\n",
    "events = client.get_ticker_events('FORTY')\n",
    "print(events.events[0])\n",
    "print(events.events[1])\n",
    "print()\n",
    "print(\"# that is wrong because it was trading under ticker FORTY since the beginning. see in aggregates API:\")\n",
    "print_aggs('FORTY', '2003-09-10', '2003-09-10')\n",
    "print(f'1063166400000 is {timestamp_to_date(1063166400000)}')\n",
    "\n",
    "print(\n",
    "'''\n",
    "# proof from flat files that FORTY was traded under ticker FORTY on 2003-09-10:\n",
    "ticker,conditions,correction,exchange,id,participant_timestamp,price,sequence_number,sip_timestamp      ,size,tape,trf_id,trf_timestamp\n",
    "\n",
    "FORTY,           ,0         ,11      ,  ,0                    ,12.13,54390          ,1063200772000000000,500 ,3   ,0,0\n",
    "FORTY,,0,12,,0,12.18,54683,1063200774000000000,500,3,0,0\n",
    "FORTY,,0,12,,0,12.02,164233,1063201566000000000,100,3,0,0\n",
    "FORTY,,0,12,,0,12,164235,1063201566000000000,300,3,0,0\n",
    "FORTY,,0,12,,0,12,186085,1063201737000000000,700,3,0,0\n",
    "FORTY,,0,3,,0,12.01,186176,1063201738000000000,300,3,0,0\n",
    "FORTY,,0,12,,0,12.02,405193,1063203807000000000,100,3,0,0\n",
    "FORTY,,0,12,,0,12.01,405213,1063203808000000000,200,3,0,0\n",
    "FORTY,,0,12,,0,12.011,451218,1063204318000000000,100,3,0,0\n",
    "FORTY,,0,12,,0,12.01,1255112,1063218714000000000,1800,3,0,0\n",
    "FORTY,,0,12,,0,12,1255113,1063218714000000000,200,3,0,0\n",
    "FORTY,,0,12,,0,12,1257062,1063218737000000000,1200,3,0,0\n",
    "FORTY,,0,3,,0,12,1257254,1063218739000000000,100,3,0,0\n",
    "FORTY,15,0,12,,0,12,1743433,1063224092000000000,0,3,0,0\n",
    "FORTY,15,0,3,,0,12,1746692,1063224185000000000,0,3,0,0\n",
    "''')\n",
    "\n",
    "print()\n",
    "print(\"# and it was never traded as FORT and FORT.Y ever:\")\n",
    "print_aggs('FORT', '2003-09-10', '2025-06-11')\n",
    "print_aggs('FORT.Y', '2003-09-10', '2025-06-11')\n",
    "\n",
    "print()\n",
    "print(\"# ticker details API also is wrong because it doesn't find FORTY before 2004-11-08:\")\n",
    "print_details('FORTY', '2004-11-01')\n",
    "print_day_of_week('2004-11-01')\n",
    "print()\n",
    "print(\"# while there were trades on 2004-11-01:\")\n",
    "print_aggs('FORTY', '2004-11-01', '2004-11-01')\n",
    "print()\n",
    "print(\"# the same on 2003-09-10:\")\n",
    "print_details('FORTY', '2003-09-10')\n",
    "print()\n",
    "print(\"# trades:\")\n",
    "print_aggs('FORTY', '2003-09-10', '2003-09-10')\n",
    "\n",
    "print()\n",
    "print(\"# history collected from active tickers also is not good because FORTY appears in it only in on 2004-11-08.\")\n",
    "print('history[\"BBG000JLM9R9\"] = {')\n",
    "pretty_print_map(history['BBG000JLM9R9'])\n",
    "print('}')\n",
    "print(\"# before 2004-11-08 there is no FORTY in tickers history. there is only FORT.Y for which there is no data in aggregates API.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "API looks unreliable. so for now my plan is to try to get the best possible data from what is available.\n",
    "\n",
    "the plan is to use the following algorithm:\n",
    "1. take the history from active tickers file.\n",
    "2. start from the first active date in the history.\n",
    "3. chose among all ticker for the same figi the one has has biggest USD volume.\n",
    "and add a check that if the ticker that was traded yesterday is also traded today and the price differs from the\n",
    "selected ticker more than 5% then log it as a potential issue.\n",
    "\n",
    "but the first step probably is to just dump all daily aggreages for all tickers in the history.\n",
    "this will speed up the process because i will not need to query the API for each ticker every time there is a doubt in\n",
    "which ticker to prefer.\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
